{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427cc260-42ef-4a70-95de-027c1304e3c4",
   "metadata": {},
   "source": [
    "<h1><center> <b><ins>Analytic Solution</ins></b> </center></h1>\n",
    "\n",
    "We will assume one has enough knowledge on how Lagrange multipliers and functions work, so we will proceed with that assumed knowledge.\n",
    "\n",
    "As a brief summary, this is a method for finding critical points of a continuously differentiable function $f:\\,\\mathbb{R}^n \\rightarrow \\mathbb{R}$ when the domain of $f$ is constrained to lie on the zero set $Z$ of a continuously differentiable function $g:\\,\\mathbb{R}^n \\rightarrow \\mathbb{R}$. Thus $Z = g^{-1}\\left(0\\right)$ and it is called the constraint set. Lagrange’s method proceeds as follows:<br>\n",
    "Define $\\mathcal{L}:\\,\\mathbb{R}^n \\times \\mathbb{R}\\,$ by $\\mathcal{L}(x, \\lambda) = f(\\mathbf{x}) − \\lambda g(\\mathbf{x})$ where $ \\mathbf{x} \\in \\mathbb{R}^{n},\\,\\,\\lambda \\in \\mathbb{R}$.<br>\n",
    "Let $\\left(x_{0}, \\lambda_{0}\\right)$ be a **critical point** of $\\mathcal{L}$ in the usual sense, that is, $\\nabla \\mathcal{L}\\left(x_{0}, \\lambda_{0}\\right) = \\mathbf{0} ∈ \\mathbb{R}^{n}$. Suppose that $\\nabla g(x_{0}) \\neq \\mathbf{0} ∈ \\mathbb{R}^{n}$. Then $x_{0}$ is a critical point of $f$ restricted to $Z$.\n",
    "\n",
    "Now let us attempt to relate this back into the context of our problem. One important thing to mention is that currently, our first constraint is in the form of an inequality. Although we can proceed with this by using a slack variable, note how we previously said that we want to be on the green part of the efficient frontier. Across this region, every possible return value has one unique risk value. This fails to hold when we introduce more than 2 assets into our portfolio, but for this case we can simply take the minimum risk value to end up with a unique value for each return. This means that regardless of how many assets we have in our portfolio, we can end up with a simple hyperbolic line that is one-to-one (our green efficient frontier). Moreover, it has a nice property that it is strictly increasing. So we can say that given a target return $\\left(\\mu^{*}\\right)$, and that we are seeking to mimimise our risk whilst meeting this target return, we can simply find a set of weights $\\left(\\mathbf{w}\\right)$ s.t $\\mathbf{w}^{T}\\boldsymbol{\\mu} = \\mu^{*}$. So we will replace our first constraint with this.\n",
    "\n",
    "So we want to find a set of weights, $\\mathbf{w}$, such that\n",
    "$$\\mathbf{w} = \\text{min}\\lbrace \\mathbf{w}^{T}\\boldsymbol{\\Sigma} \\mathbf{w}\\rbrace$$\n",
    "$$\\text{s.t}\\,\\,\\,\\,\\mathbf{w}^{T}\\boldsymbol{\\mu} = \\mu^{*},\\,\\,\\lVert \\mathbf{w} \\rVert_{1}=1\\,\\,\\text{and}\\,\\,w_{i}\\ge 0,\\,\\,\\forall i \\in \\left[1,k\\right]$$\n",
    "where $\\mu^{*}$ represents some target return value that we would like to exceed.\n",
    "\n",
    "In the context of our problem we have:\n",
    "\n",
    "- A continuously differentiable function $f:\\,\\mathbb{R}^k \\rightarrow \\mathbb{R}$ s.t $f\\left(\\mathbf{w}\\right) = \\mathbf{w}^{T}\\boldsymbol{\\Sigma} \\mathbf{w}$\n",
    "- A continuously differentiable function $g_{1}:\\,\\mathbb{R}^k \\rightarrow \\mathbb{R}$ s.t $g_{1}\\left(\\mathbf{w}\\right) = \\mathbf{w}^{T}\\boldsymbol{\\mu} - \\mu^{*}$.<br>Note how $g_{1} \\equiv 0,\\,\\,\\forall\\,\\mathbf{w} \\in \\mathbb{R}^{k}$, since our first constraint is that $\\mathbf{w}^{T}\\boldsymbol{\\mu} = \\mu^{*}$.\n",
    "- A continuously differentiable function $g_{2}:\\,\\mathbb{R}^k \\rightarrow \\mathbb{R}$ s.t $g_{2}\\left(\\mathbf{w}\\right) = \\mathbf{w}^{T}\\mathbf{1} - 1$.<br>Note how $g_{2} \\equiv 0,\\,\\,\\forall\\,\\mathbf{w} \\in \\mathbb{R}^{k}$, since our second constraint is that $\\mathbf{w}^{T}\\mathbf{1} = 1$.\n",
    "\n",
    "Writing out our Lagrangian function $\\mathcal{L}:\\,\\mathbb{R}^k \\times \\mathbb{R}^{2}$, we get\n",
    "$$\\mathcal{L}\\left(\\mathbf{w}, \\boldsymbol{\\lambda}\\right) = \\mathbf{w}^{T}\\boldsymbol{\\Sigma} \\mathbf{w} - \\lambda_{1}\\left(\\mathbf{w}^{T}\\boldsymbol{\\mu} - \\mu^{*}\\right) - \\lambda_{2}\\left(\\mathbf{w}^{T}\\mathbf{1} - 1\\right)$$\n",
    "where $\\boldsymbol{\\lambda} = \\begin{pmatrix}\\lambda_{1}\\\\ \\lambda_{2}\\end{pmatrix}$ are the Lagrange multipliers.\n",
    "\n",
    "Now we calculate $\\nabla \\mathcal{L}\\left(\\mathbf{w}, \\boldsymbol{\\lambda}\\right)$ which we define as $\\left(\\nabla_{\\mathbf{w}} \\mathcal{L},\\,\\,\\nabla_{\\lambda_{1}} \\mathcal{L},\\,\\,\\nabla_{\\lambda_{2}} \\mathcal{L}\\right)$.\n",
    "\n",
    "$$\\nabla_{\\mathbf{w}} \\mathcal{L} = \\nabla_{\\mathbf{w}}\\left[\\mathbf{w}^{T}\\boldsymbol{\\Sigma} \\mathbf{w} - \\lambda_{1}\\left(\\mathbf{w}^{T}\\boldsymbol{\\mu} - \\mu^{*}\\right) - \\lambda_{2}\\left(\\mathbf{w}^{T}\\mathbf{1} - 1\\right)\\right]$$\n",
    "Recalling some simple matrix calculus, we can use the product rule combined with the fact all covariance matrices are symmetric to say\n",
    "$$\\nabla_{\\mathbf{w}}\\left(\\mathbf{w}^{T}\\boldsymbol{\\Sigma} \\mathbf{w}\\right) = 2\\boldsymbol{\\Sigma}\\mathbf{w}$$\n",
    "Therefore,\n",
    "$$\\nabla_{\\mathbf{w}} \\mathcal{L} = 2\\boldsymbol{\\Sigma}\\mathbf{w} - \\lambda_{1}\\boldsymbol{\\mu} - \\lambda_{2}\\mathbf{1}$$\n",
    "\n",
    "And clearly,\n",
    "$$\\nabla_{\\lambda_{1}} \\mathcal{L} = -\\mathbf{w}^{T}\\boldsymbol{\\mu} + \\mu^{*}$$\n",
    "$$\\nabla_{\\lambda_{2}} \\mathcal{L} = -\\mathbf{w}^{T}\\mathbf{1} + 1$$\n",
    "\n",
    "Upon equating $\\nabla \\mathcal{L} = \\left(0,0,0\\right)$, we get 3 equations:\n",
    "$$2\\boldsymbol{\\Sigma}\\mathbf{w} - \\lambda_{1}\\boldsymbol{\\mu} - \\lambda_{2}\\mathbf{1} = 0$$\n",
    "$$-\\mathbf{w}^{T}\\boldsymbol{\\mu} + \\mu^{*} = 0$$\n",
    "$$-\\mathbf{w}^{T}\\mathbf{1} + 1 = 0$$\n",
    "\n",
    "From the first, we can rearrage it to solve for $\\mathbf{w}$ and we get\n",
    "$$\\mathbf{w} = \\frac{1}{2}\\boldsymbol{\\Sigma}^{-1}\\left(\\lambda_{1}\\boldsymbol{\\mu} + \\lambda_{2}\\mathbf{1}\\right)$$\n",
    "Here we are assuming that our covariance matrix is invertible which is true for most, but not all. If we do have a singular matrix, we can simply take the pseudo-inverse instead. We will make this clear in our code later.\n",
    "\n",
    "We can make this equation for $\\mathbf{w}$ much simpler by letting\n",
    "$$\\mathbf{U} = \\begin{pmatrix}\\boldsymbol{\\mu} & \\mathbf{1}\\end{pmatrix} \\in \\mathbb{R}^{k \\times 2}$$\n",
    "Now\n",
    "$$\\mathbf{w} = \\frac{1}{2}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U}\\boldsymbol{\\lambda}$$\n",
    "\n",
    "We can solve for $\\boldsymbol{\\lambda}$ while adhering to the equation for $\\mathbf{w}$ by plugging this into the second and third equations above. This results in\n",
    "$$\\mu^{*} = \\mathbf{w}^{T}\\boldsymbol{\\mu} = \\boldsymbol{\\mu}^{T}\\mathbf{w} = \\frac{1}{2}\\boldsymbol{\\mu}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U}\\boldsymbol{\\lambda}$$\n",
    "$$1 = \\mathbf{w}^{T}\\mathbf{1} = \\mathbf{1}^{T}\\mathbf{w} = \\frac{1}{2}\\mathbf{1}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U}\\boldsymbol{\\lambda}$$\n",
    "\n",
    "We can write this system of linear equations in matrix form to say\n",
    "$$\\begin{pmatrix}\\mu^{*} \\\\ 1\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}\\boldsymbol{\\mu}^{T} \\\\ \\mathbf{1}^{T}\\end{pmatrix}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U}\\boldsymbol{\\lambda}$$\n",
    "And by letting $\\mathbf{u} = \\begin{pmatrix}\\mu^{*} \\\\ 1\\end{pmatrix} \\in \\mathbb{R}^{2 \\times 1}$,\n",
    "$$\\mathbf{u} = \\frac{1}{2}\\mathbf{U}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U}\\boldsymbol{\\lambda}$$\n",
    "\n",
    "Due to the dimensions of $\\mathbf{U}$ and $\\boldsymbol{\\Sigma}$, we can let $\\mathbf{A} = \\mathbf{U}^{T}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U} \\in \\mathbb{R}^{2 \\times 2}$. And so\n",
    "$$\\mathbf{u} = \\frac{1}{2}\\mathbf{A}\\boldsymbol{\\lambda}$$\n",
    "$$\\implies \\boldsymbol{\\lambda} = 2\\mathbf{A}^{-1}\\mathbf{u}$$\n",
    "\n",
    "Substituting this into (),\n",
    "$$\\mathbf{w} = \\frac{1}{2}\\boldsymbol{\\Sigma}^{-1}\\mathbf{U}2\\mathbf{A}^{-1}\\mathbf{u} = \\boldsymbol{\\Sigma}^{-1}\\mathbf{U}\\mathbf{A}^{-1}\\mathbf{u}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f0c74-b13b-4bbc-bde6-5ab334367fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
